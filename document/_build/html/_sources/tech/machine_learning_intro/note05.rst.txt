第５回
=========================

過適合
---------------------
訓練データセットに対してモデルパラメータのサイズが大きい場合（過剰決定のケース）に、訓練データに対しては100%の再現ができるが、分布の推定としては全く役に立たない場合がある。モデルパラメータは、訓練データセットを再現するのが目的なのではなく、データセットの背後に在る（と存在論的に仮定される）分布を再現するのが目的である。

正則化
----------------------
モデルパラメータのもとでのデータのコストに、モデルパラメータに対する制約としての罰金項を加えて最適化する。
　罰金項は、モデルパラメータに対するパラメータを選択してその形を決めてやるので、そのパラメータを、ハイパーパラメータという。

正則化とベイズ推論
----------------------------
罰金項をパラメータの事前分布と対応付けることで、正則化をベイズ推論における事後分布最大化推定（MAP推定）とみなすことができる。

LASSOによるスパース回帰
-------------------------------


モデル/ハイパーパラメータ選択
--------------------------------------------
データ解析の一般的な問題では、そのデータが従う分布のモデルは知らないことが前提とされている。

このような場合、モデルパラメータと基底関数の多くて複雑なモデルに正則化を付けておけばある程度柔軟に対応することができる。

ここで新たに生じる問題として、モデルや正則化のためのハイパーパラメータを決定する自由度がある。 **モデル/ハイパーパラメータ選択問題**

この問題に対する代表的なアプローチ
- 汎化誤差最小化
- 経験ベイズ法（周辺尤度最大化）

 この２つは計算量がかかる

- 情報量基準

訓練誤差と汎化誤差
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
モデルが複雑になる　ー＞　訓練データへの当てはまりが良くなる
ー＞　訓練データ以外の点での真の分布とのズレが大きく、確定的になる。

したがって、推定の目的は、訓練誤差の最小化ではなく、汎化誤差を最小化にある。そこで、

- クロスヴァリデーション
- ブートストラップメソッド

などにより検証誤差を汎化誤差の代替として最小化するようなモデル・ハイパーパラメータを選ぶ。


訓練、検証、テスト分割
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
検証誤差は不偏推定量ではない。必ず汎化誤差が過小評価される。したがって、手元に在るデータセットを３分割して、訓練、検証、テスト用に分割して検証するのがいい。


経験ベイズ法
-----------------------------------

情報量基準
------------------------------
データセットに加えて、統計/学習モデルに何らかのモデルを導入することで汎化誤差を解析的に見積もる。
